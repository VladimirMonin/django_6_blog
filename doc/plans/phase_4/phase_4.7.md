# Фаза 4.7: Сервис векторизации (OpenAI API)

## Цель

Создать сервис для получения векторных представлений чанков через OpenAI API.

---

## Контекст

После чанкинга (фаза 4.6) каждый фрагмент текста нужно преобразовать в вектор (эмбеддинг). Мы используем модель OpenAI `text-embedding-3-small` (размерность 1536), которая обеспечивает хороший баланс качества и стоимости.

**Ключевые оптимизации:**
- **Batch-запросы** — отправка 20-50 чанков за раз для минимизации сетевых накладных расходов
- **Кэширование через `content_hash`** — если хеш чанка уже есть в БД с эмбеддингом, пропускаем API-вызов
- **Retry с Exponential Backoff** — при ошибках 429 (Rate Limit) или 503 повторяем с задержкой

Подсчёт стоимости через `tiktoken` позволяет оценить расходы до отправки запроса.

**Философия:** Не платить за то, что уже вычислено.

**Документация:**
- [ИИ поиск на базе смыслов — концепция](../researches/report_6/ИИ%20поиск%20на%20базе%20смыслов%20-%20концепция.md) — "ШАГ C: Оркестрация векторизации"
- [Django, pgvector: семантический поиск локально](../researches/report_6/Django,%20pgvector_%20семантический%20поиск%20локально.md) — раздел 4.2 "Менеджеры и QuerySet для векторизации"

---

## Задачи

### Установка зависимостей

- [ ] Установить OpenAI SDK: `poetry add openai`
- [ ] Убедиться, что tiktoken установлен (из фазы 4.6)
- [ ] Добавить `OPENAI_API_KEY` в `.env`

### Создание сервиса

- [ ] Создать файл `blog/services/vectorization_service.py`
- [ ] Определить функцию `vectorize_chunks(chunks: list[ChunkData]) -> list[ChunkData]`
- [ ] Функция обогащает чанки полем `embedding` и возвращает обновлённый список

### Логика кэширования

- [ ] Для каждого чанка вычислить `content_hash` (SHA256 от content)
- [ ] Проверить в БД: существует ли `TextChunk` с таким хешем и непустым `embedding`
- [ ] Если да — использовать существующий эмбеддинг, не вызывать API
- [ ] Формировать список только новых чанков для векторизации

### Batch-обработка

- [ ] Разбить список новых чанков на батчи по 20-50 штук
- [ ] Для каждого батча вызвать `client.embeddings.create()`
- [ ] Использовать модель `text-embedding-3-small`
- [ ] Собрать результаты и сопоставить с чанками по индексу

### Обработка ошибок

- [ ] Обернуть API-вызовы в try/except
- [ ] При ошибке 429 (Rate Limit) — ждать и повторять с экспоненциальной задержкой
- [ ] При ошибке 503 (Service Unavailable) — аналогично
- [ ] Логировать все ошибки для отладки
- [ ] Установить максимальное количество повторов (например, 3)

### Подсчёт стоимости

- [ ] Создать функцию `estimate_cost(chunks: list[ChunkData]) -> dict`
- [ ] Использовать tiktoken для подсчёта токенов
- [ ] Вернуть: общее количество токенов, примерную стоимость в долларах
- [ ] Актуальные тарифы: ~$0.02 / 1M токенов для text-embedding-3-small

### Конфигурация

- [ ] Вынести параметры в settings: `OPENAI_EMBEDDING_MODEL`, `OPENAI_BATCH_SIZE`
- [ ] Значения по умолчанию: `text-embedding-3-small`, 20

---

## Тестирование

- [ ] Создать тестовый чанк и вызвать векторизацию
- [ ] Проверить, что эмбеддинг имеет размерность 1536
- [ ] Повторно вызвать векторизацию — API не должен вызываться (кэш)
- [ ] Протестировать estimate_cost на наборе чанков

---

## Коммит

```
phase 4.7 feat: Сервис векторизации (OpenAI API)
- Создан blog/services/vectorization_service.py
- Реализована batch-векторизация через OpenAI API
- Добавлено кэширование через content_hash
- Реализован retry с exponential backoff
- Добавлена функция estimate_cost для оценки расходов
```
